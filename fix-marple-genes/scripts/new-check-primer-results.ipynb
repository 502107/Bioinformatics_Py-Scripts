{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step1: Extract the genes that passed the wet lab tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pass = pd.read_excel('../part1/pass_primers-pst-2024.xlsx', usecols=[1,3,5])\n",
    "combined_df = pd.concat([pd.read_csv(f) for f in glob.glob('../part1/primer-batches/*.csv')],ignore_index=True)\n",
    "df_pass = df_pass.merge(combined_df[['PrimerSeq_F', 'PrimerLoc_F', 'PrimerLoc_R','GeneLength_no_padding', 'GeneLength_with_padding','Primer_coverage']],on='PrimerSeq_F',how='left')\n",
    "df_pass.to_csv('../part1/edited-pass_primers-pst-2024.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_dir = '../REF'\n",
    "ref_fasta = os.path.join(ref_dir,'new_reference_all_genes','pst104e.fasta')\n",
    "ref_gff3 = os.path.join(ref_dir,'new_reference_all_genes','pst104e.gff3')\n",
    "out_fasta = os.path.join(ref_dir,'new_reference_marple_genes','new_pst104e_marple_genes.fasta')\n",
    "out_gff3 = os.path.join(ref_dir,'new_reference_marple_genes','new_pst104e_marple_genes.gff3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step2: Fix gene naming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting gene sequences from reference...\n",
      "Extracted 30249 genes from GFF3\n",
      "Dropped 29 rows with empty important fields\n",
      "Updated primers saved to ../updated_primers_new-code.csv\n",
      "Gene ID changes saved to ../gene_id_changes.csv\n",
      "Total gene ID changes: 26\n",
      "Completed missing fields for 294 genes\n",
      "List of genes with completed fields saved to completed_fields.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "import re\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "\n",
    "def reverse_complement(seq):\n",
    "    complement = {'A': 'T', 'C': 'G', 'G': 'C', 'T': 'A'}\n",
    "    return ''.join([complement.get(base, base) for base in reversed(seq)])\n",
    "\n",
    "def extract_gene_sequences(gff_file, fasta_file, padding=0):\n",
    "    genome = {}\n",
    "    for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "        genome[record.id] = str(record.seq)\n",
    "    \n",
    "    genes = {}\n",
    "    with open(gff_file, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith('#'):\n",
    "                continue\n",
    "            fields = line.strip().split('\\t')\n",
    "            if len(fields) < 9 or fields[2].lower() != 'gene':\n",
    "                continue\n",
    "                \n",
    "            chrom = fields[0]\n",
    "            start = int(fields[3])\n",
    "            end = int(fields[4])\n",
    "            strand = fields[6]\n",
    "            \n",
    "            attributes = fields[8]\n",
    "            match = re.search(r'ID=([^;]+)', attributes) or re.search(r'gene_id=([^;]+)', attributes)\n",
    "            if not match:\n",
    "                continue\n",
    "            gene_id = match.group(1)\n",
    "            \n",
    "            if chrom in genome:\n",
    "                padded_start = max(1, start - padding)\n",
    "                padded_end = min(len(genome[chrom]), end + padding)\n",
    "                sequence = genome[chrom][padded_start-1:padded_end]\n",
    "                \n",
    "                genes[gene_id] = {\n",
    "                    'chrom': chrom,\n",
    "                    'start': start,\n",
    "                    'end': end,\n",
    "                    'strand': strand,\n",
    "                    'sequence': sequence,\n",
    "                    'padded_start': padded_start,\n",
    "                    'padded_end': padded_end,\n",
    "                    'length_no_padding': end - start + 1,\n",
    "                    'length_with_padding': padded_end - padded_start + 1\n",
    "                }\n",
    "    \n",
    "    return genes\n",
    "\n",
    "def find_primer_locations(sequence, primer_f, primer_r):\n",
    "    \"\"\"Find primer locations considering multiple possible orientations.\"\"\"\n",
    "    # Get reverse complements\n",
    "    primer_f_rc = reverse_complement(primer_f)\n",
    "    primer_r_rc = reverse_complement(primer_r)\n",
    "    \n",
    "    # Store all possible valid primer arrangements\n",
    "    valid_arrangements = []\n",
    "    \n",
    "    # Case 1: Standard orientation (Forward → Reverse complement)\n",
    "    f_loc = sequence.find(primer_f)\n",
    "    r_rc_loc = sequence.find(primer_r_rc)\n",
    "    \n",
    "    if f_loc >= 0 and r_rc_loc >= 0 and f_loc < r_rc_loc:\n",
    "        valid_arrangements.append({\n",
    "            'f_loc': f_loc + 1,  # 1-based coordinate\n",
    "            'r_loc': r_rc_loc + len(primer_r_rc),\n",
    "            'amplicon_size': r_rc_loc - f_loc + len(primer_r_rc)\n",
    "        })\n",
    "    \n",
    "    # Case 2: Reversed primer pair (Reverse → Forward complement)\n",
    "    r_loc = sequence.find(primer_r)\n",
    "    f_rc_loc = sequence.find(primer_f_rc)\n",
    "    \n",
    "    if r_loc >= 0 and f_rc_loc >= 0 and r_loc < f_rc_loc:\n",
    "        valid_arrangements.append({\n",
    "            'f_loc': r_loc + 1,  # Reverse primer now acts as forward\n",
    "            'r_loc': f_rc_loc + len(primer_f_rc),\n",
    "            'amplicon_size': f_rc_loc - r_loc + len(primer_f_rc)\n",
    "        })\n",
    "    \n",
    "    # Case 3: Circular arrangement (Forward at end, Reverse complement at beginning)\n",
    "    if f_loc >= 0 and r_rc_loc >= 0 and f_loc > r_rc_loc:\n",
    "        valid_arrangements.append({\n",
    "            'f_loc': f_loc + 1,\n",
    "            'r_loc': r_rc_loc + len(primer_r_rc),\n",
    "            'amplicon_size': len(sequence) - f_loc + r_rc_loc + len(primer_r_rc)  # Wraparound size\n",
    "        })\n",
    "    \n",
    "    # Case 4: Reversed circular (Reverse at end, Forward complement at beginning)\n",
    "    if r_loc >= 0 and f_rc_loc >= 0 and r_loc > f_rc_loc:\n",
    "        valid_arrangements.append({\n",
    "            'f_loc': r_loc + 1,\n",
    "            'r_loc': f_rc_loc + len(primer_f_rc),\n",
    "            'amplicon_size': len(sequence) - r_loc + f_rc_loc + len(primer_f_rc)  # Wraparound size\n",
    "        })\n",
    "    \n",
    "    # If any valid arrangement found, return the one with smallest amplicon size\n",
    "    if valid_arrangements:\n",
    "        best_match = min(valid_arrangements, key=lambda x: x['amplicon_size'])\n",
    "        return best_match['f_loc'], best_match['r_loc']\n",
    "    \n",
    "    return None, None\n",
    "\n",
    "\n",
    "def update_primers_with_correct_genes(primers_csv, gff_file, fasta_file, output_csv, changes_csv, padding=1000):\n",
    "    primers_df = pd.read_csv(primers_csv)\n",
    "    \n",
    "    print(\"Extracting gene sequences from reference...\")\n",
    "    genes = extract_gene_sequences(gff_file, fasta_file, padding)\n",
    "    print(f\"Extracted {len(genes)} genes from GFF3\")\n",
    "    \n",
    "    changes = []\n",
    "    missing_fields_completed = []\n",
    "    \n",
    "    # For each primer pair, find the correct gene\n",
    "    updated_rows = []\n",
    "    for _, row in primers_df.iterrows():\n",
    "        original_gene_id = row['GeneID']\n",
    "        primer_f = row['PrimerSeq_F']\n",
    "        primer_r = row['PrimerSeq_R']\n",
    "        \n",
    "        best_match = None\n",
    "        best_f_loc = None\n",
    "        best_r_loc = None\n",
    "        \n",
    "        # Check if the current gene ID exists in our genes dictionary\n",
    "        if original_gene_id in genes:\n",
    "            # Check if the primers match this gene\n",
    "            sequence = genes[original_gene_id]['sequence']\n",
    "            f_loc, r_loc = find_primer_locations(sequence, primer_f, primer_r)\n",
    "            \n",
    "            if f_loc is not None and r_loc is not None:\n",
    "                best_match = original_gene_id\n",
    "                best_f_loc = f_loc\n",
    "                best_r_loc = r_loc\n",
    "                best_gene_info = genes[original_gene_id]\n",
    "        \n",
    "        # If no match found with the original gene ID, search all genes\n",
    "        if best_match is None:\n",
    "            for gene_id, gene_info in genes.items():\n",
    "                sequence = gene_info['sequence']\n",
    "                f_loc, r_loc = find_primer_locations(sequence, primer_f, primer_r)\n",
    "\n",
    "                if f_loc is not None and r_loc is not None:\n",
    "                    # Found a match\n",
    "                    best_match = gene_id\n",
    "                    best_f_loc = f_loc\n",
    "                    best_r_loc = r_loc\n",
    "                    best_gene_info = gene_info\n",
    "                    break  # Take the first match\n",
    "        \n",
    "        new_row = row.copy()\n",
    "        \n",
    "        # Case 1: Found a different gene match\n",
    "        if best_match and best_match != original_gene_id:\n",
    "            changes.append((original_gene_id, best_match))\n",
    "            \n",
    "            # Update gene ID and locations\n",
    "            new_row['GeneID'] = best_match\n",
    "            new_row['PrimerLoc_F'] = best_f_loc\n",
    "            new_row['PrimerLoc_R'] = best_r_loc\n",
    "            new_row['GeneLength_no_padding'] = best_gene_info['length_no_padding']\n",
    "            new_row['GeneLength_with_padding'] = best_gene_info['length_with_padding']\n",
    "            new_row['Primer_coverage'] = best_r_loc - best_f_loc + 1\n",
    "        \n",
    "        # Case 2: Same gene match but need to complete missing fields\n",
    "        elif best_match and best_match == original_gene_id:\n",
    "            # Check for missing or zero values in important fields\n",
    "            fields_updated = False\n",
    "            \n",
    "            # List of fields to check and update if missing\n",
    "            fields_to_check = [\n",
    "                ('PrimerLoc_F', best_f_loc),\n",
    "                ('PrimerLoc_R', best_r_loc),\n",
    "                ('GeneLength_no_padding', best_gene_info['length_no_padding']),\n",
    "                ('GeneLength_with_padding', best_gene_info['length_with_padding'])\n",
    "            ]\n",
    "            \n",
    "            for field_name, new_value in fields_to_check:\n",
    "                # Check if field is missing, empty, or zero\n",
    "                # if field_name not in new_row or pd.isna(new_row[field_name]) or new_row[field_name] == 0:\n",
    "                new_row[field_name] = new_value\n",
    "                fields_updated = True\n",
    "            \n",
    "            # Calculate primer coverage if missing\n",
    "            if 'Primer_coverage' not in new_row or pd.isna(new_row['Primer_coverage']) or new_row['Primer_coverage'] == 0:\n",
    "                new_row['Primer_coverage'] = best_r_loc - best_f_loc + 1\n",
    "                fields_updated = True\n",
    "                \n",
    "            if fields_updated:\n",
    "                missing_fields_completed.append(original_gene_id)\n",
    "                \n",
    "        updated_rows.append(new_row)\n",
    "    \n",
    "    # Create DataFrame from updated rows\n",
    "    updated_df = pd.DataFrame(updated_rows)\n",
    "    \n",
    "    # Drop rows with empty important fields\n",
    "    original_count = len(updated_df)\n",
    "    important_fields = ['GeneID', 'PrimerSeq_F', 'PrimerSeq_R', 'PrimerLoc_F', 'PrimerLoc_R']\n",
    "    updated_df = updated_df.dropna(subset=important_fields)\n",
    "    rows_dropped = original_count - len(updated_df)\n",
    "    \n",
    "    if rows_dropped > 0:\n",
    "        print(f\"Dropped {rows_dropped} rows with empty important fields\")\n",
    "    \n",
    "    # Save updated primers\n",
    "    updated_df.to_csv(output_csv, index=False)\n",
    "    print(f\"Updated primers saved to {output_csv}\")\n",
    "    \n",
    "    # Save changes\n",
    "    if changes:\n",
    "        with open(changes_csv, 'w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(['Original_GeneID', 'New_GeneID'])\n",
    "            writer.writerows(changes)\n",
    "        print(f\"Gene ID changes saved to {changes_csv}\")\n",
    "        print(f\"Total gene ID changes: {len(changes)}\")\n",
    "    \n",
    "    # Report on completed fields\n",
    "    if missing_fields_completed:\n",
    "        print(f\"Completed missing fields for {len(missing_fields_completed)} genes\")\n",
    "        with open('../part1/completed_fields.csv', 'w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(['GeneID'])\n",
    "            for gene_id in missing_fields_completed:\n",
    "                writer.writerow([gene_id])\n",
    "        print(f\"List of genes with completed fields saved to completed_fields.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    primers_csv = \"../part1/edited-pass_primers-pst-2024.csv\"\n",
    "    gff_file = ref_gff3\n",
    "    fasta_file = ref_fasta\n",
    "    output_csv = \"../part1/updated_primers_new-code.csv\"\n",
    "    changes_csv = \"../part1/gene_id_changes.csv\"\n",
    "    \n",
    "    update_primers_with_correct_genes(primers_csv, gff_file, fasta_file, output_csv, changes_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step3: Create a new reference assembly for PST104E, based on those genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gffutils\n",
    "from Bio import SeqIO\n",
    "from Bio.SeqRecord import SeqRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_genes(gff3_path, fasta_path, gene_ids, output_fasta):\n",
    "    db_path = os.path.splitext(gff3_path)[0] + '.db'\n",
    "    if not os.path.exists(db_path):\n",
    "        gffutils.create_db(gff3_path, db_path, merge_strategy='create_unique')\n",
    "    \n",
    "    db = gffutils.FeatureDB(db_path)\n",
    "    scaffold_records = SeqIO.to_dict(SeqIO.parse(fasta_path, \"fasta\"))\n",
    "    \n",
    "    extracted_records = []\n",
    "    for gene_id in gene_ids:\n",
    "        try:\n",
    "            gene = db[gene_id]\n",
    "        except KeyError:\n",
    "            print(f\"Warning: Gene {gene_id} not found in GFF3\")\n",
    "            continue\n",
    "        \n",
    "        scaffold_id = gene.seqid\n",
    "        if scaffold_id not in scaffold_records:\n",
    "            print(f\"Warning: Scaffold {scaffold_id} not found in FASTA\")\n",
    "            continue\n",
    "        \n",
    "        scaffold_seq = scaffold_records[scaffold_id].seq\n",
    "        start = max(0, gene.start - 1)  # 0-based\n",
    "        end = gene.end\n",
    "        gene_seq = scaffold_seq[start:end]\n",
    "        \n",
    "        new_record = SeqIO.SeqRecord(\n",
    "            gene_seq,\n",
    "            id=gene_id,\n",
    "            # description=f\"+/- {padding} kb\"\n",
    "        )\n",
    "        extracted_records.append(new_record)\n",
    "        # print(f\"Length of {gene_id}: {len(gene_seq)}\")\n",
    "        \n",
    "    SeqIO.write(extracted_records, output_fasta, \"fasta\")\n",
    "    return extracted_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def adapt_gff3(gff3_path, gene_ids, output_gff3):\n",
    "    db_path = os.path.splitext(gff3_path)[0] + '.db'\n",
    "    if not os.path.exists(db_path):\n",
    "        gffutils.create_db(gff3_path, db_path, merge_strategy='create_unique')\n",
    "    \n",
    "    db = gffutils.FeatureDB(db_path)\n",
    "    adapted_features = []\n",
    "    \n",
    "    for gene_id in gene_ids:\n",
    "        try:\n",
    "            gene = db[gene_id]\n",
    "        except KeyError:\n",
    "            print(f\"Warning: Gene {gene_id} not found in GFF3\")\n",
    "            continue\n",
    "        \n",
    "        original_start = gene.start\n",
    "        original_end = gene.end\n",
    "        gene_length = original_end - original_start + 1\n",
    "        \n",
    "        # gene.start = 1001\n",
    "        # gene.end = 1000 + gene_length\n",
    "        gene.start = 1\n",
    "        gene.end = gene_length\n",
    "        gene.seqid = gene_id\n",
    "        adapted_features.append(gene)\n",
    "        \n",
    "        def get_all_children(parent_id):\n",
    "            children = []\n",
    "            for child in db.children(parent_id):\n",
    "                children.append(child)\n",
    "                children.extend(get_all_children(child.id))\n",
    "            return children\n",
    "        \n",
    "        for child in get_all_children(gene_id):\n",
    "            if child.id == gene_id:\n",
    "                continue\n",
    "            \n",
    "            # child.start = child.start - original_start + 1001\n",
    "            # child.end = child.end - original_start + 1001\n",
    "            child.start = child.start - original_start + 1\n",
    "            child.end = child.end - original_start + 1\n",
    "            child.seqid = gene_id\n",
    "            adapted_features.append(child)\n",
    "    \n",
    "    with open(output_gff3, 'w') as f:\n",
    "        for feature in adapted_features:\n",
    "            f.write(str(feature) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_list_of_genes = pd.read_csv('../part1/updated_primers_new-code.csv')['GeneID'].unique()\n",
    "extract_genes(ref_gff3,ref_fasta, new_list_of_genes, out_fasta)\n",
    "adapt_gff3(ref_gff3, new_list_of_genes, out_gff3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
